
# Python imports
import os
import hmac
from os import environ
from datetime import datetime
from sys import platform
import hashlib
from concurrent.futures import ThreadPoolExecutor

# External imports
import streamlit as st
from openai import OpenAI

# Local imports
from functions.transcribe import transcribe_with_whisper_openai
from functions.llm import process_text_openai
from functions.voice import text_to_speech
from functions.mix_audio import mix_music_and_voice
from functions.split_audio import split_audio_to_chunks
from functions.styling import page_configuration, page_styling
import prompts as p
import config as c


### INITIAL VARIABLES

# Creates folder if they don't exist
os.makedirs("data/audio", exist_ok=True) # Where audio/video files are stored for transcription
os.makedirs("data/audio/audio_chunks", exist_ok=True) # Where audio/video files are stored for transcription


st.session_state["pwd_on"] = st.secrets.pwd_on

### PASSWORD

if st.session_state["pwd_on"] == "true":

    def check_password():

        passwd = st.secrets["password"]

        def password_entered():

            if hmac.compare_digest(st.session_state["password"], passwd):
                st.session_state["password_correct"] = True
                del st.session_state["password"]  # Don't store the password.
            else:
                st.session_state["password_correct"] = False

        if st.session_state.get("password_correct", False):
            return True

        st.text_input("L√∂senord", type="password", on_change=password_entered, key="password")
        if "password_correct" in st.session_state:
            st.error("üòï Ooops. Fel l√∂senord.")
        return False


    if not check_password():
        st.stop()


# Check and set default values if not set in session_state
# of Streamlit

if "spoken_language" not in st.session_state: # What language source audio is in
    st.session_state["spoken_language"] = "Automatiskt"
if "file_name_converted" not in st.session_state: # Audio file name
    st.session_state["file_name_converted"] = None
if "gpt_template" not in st.session_state: # Audio file name
    st.session_state["gpt_template"] = "Ljus r√∂st - Glad, positiv och sv√§r g√§rna"
if "llm_temperature" not in st.session_state:
    st.session_state["llm_temperature"] = c.llm_temp
if "llm_chat_model" not in st.session_state:
    st.session_state["llm_chat_model"] = c.llm_model
if "audio_file" not in st.session_state:
    st.session_state["audio_file"] = False


# Checking if uploaded or recorded audio file has been transcribed
def compute_file_hash(uploaded_file):

    print("\nSTART: Check if audio file has been transcribed - hash")

    # Compute the MD5 hash of a file
    hasher = hashlib.md5()
    
    for chunk in iter(lambda: uploaded_file.read(4096), b""):
        hasher.update(chunk)
    uploaded_file.seek(0)  # Reset the file pointer to the beginning

    print("DONE: Check if audio file has been transcribed - hash")
    
    return hasher.hexdigest()



### MAIN APP ###########################

page_configuration()
page_styling()


def main():

    global translation
    global model_map_transcribe_model


    ### SIDEBAR

    st.sidebar.markdown(
        f"""# Ber√∂mfabriken
Det h√§r √§r en av flera prototyper som togs fram till projektet 'Top of Mind: 
J√§mst√§lldhet i industrins vardag.  
https://www.ri.se/sv/vad-vi-gor/projekt/top-of-mind-jamstalldhet-i-industrins-vardag

---

Micke Kring
RISE

mikael.kring@ri.se

---

Version: {c.app_version}  
Uppdaterad: {c.app_updated}

        """
        )


    ### ### ### ### ### ### ### ### ### ### ###
    ### MAIN PAGE
    
    topcol1, topcol2 = st.columns([2, 2], gap="large")

    with topcol1:
        # Title
        st.markdown(f"""## :material/thumb_up: {c.app_name}""")
        st.markdown("""Klicka p√• __mikrofonsymbolen__ h√§r under f√∂r att spela in ditt ber√∂m till din kollega. N√§r du √§r 
            klar trycker du p√• __stoppsymbolen__. V√§nta tills ditt tal gjorts om till text och 
            v√§lj sedan en mall f√∂r ber√∂m.""")

        
    with topcol2:

        with st.expander(":material/help: Vill du ha tips?"):
            st.markdown("""__Att ge ber√∂m till en kollega kan k√§nnas lite pinsamt, men forskning har visat att 
det kan f√• oss att m√• b√§ttre p√• jobbet och att vi till och med blir mer produktiva. 
Att f√• h√∂ra att kollegor v√§rdes√§tter och uppm√§rksammar en √∂kar ens v√§lm√•ende helt enkelt.__

Det viktigaste √§r att det kommer fr√•n hj√§rtat och ett spontant ber√∂m kommer du l√•ngt med.
Men om du vill ha n√•gra tips, s√• f√∂rs√∂k att vara specifik. Ber√§tta vad det √§r du tycker din 
kollega g√∂r s√• bra och hur det f√•r dig att k√§nna. I st√§llet f√∂r att bara s√§ga ‚Äòbra jobbat‚Äô, 
n√§mn n√•got konkret, som ‚Äòjag uppskattar verkligen att du kan h√•lla lugnet under press.‚Äô 

Du kan ocks√• ge ber√∂m b√•de f√∂r prestationer och egenskaper. Du kan ber√∂mma hur n√•gon l√∂ser 
ett problem, men √§ven deras samarbetsf√∂rm√•ga, empati eller hur de st√∂ttar andra i teamet.

Kom ih√•g att √§ven vara j√§mst√§lld i hur du ger ber√∂m. Se till att alla f√•r erk√§nnande f√∂r 
sina insatser, oavsett k√∂n, titel eller bakgrund. Det hj√§lper till att skapa ett mer 
inkluderande arbetsklimat.

Och till sist, var √§rlig. M√§nniskor k√§nner av n√§r ber√∂m √§r genuint. S√• n√§r du ser n√•got bra ‚Äì s√§g det!
Att regelbundet ge ber√∂m bygger upp tillit, respekt och en arbetsplats d√§r alla k√§nner sig 
sedda och uppskattade.
""")


    maincol1, maincol2 = st.columns([2, 2], gap="large")


    with maincol1:

        st.markdown("#### Ber√∂m din kollega")

        audio = st.experimental_audio_input("Spela in ett r√∂stmeddelande", label_visibility = "collapsed")

        if audio:
            current_file_hash = compute_file_hash(audio)

            # If the uploaded file hash is different from the one in session state, reset the state
            if "file_hash" not in st.session_state or st.session_state.file_hash != current_file_hash:
                st.session_state.file_hash = current_file_hash
                
                if "transcribed" in st.session_state:
                    del st.session_state.transcribed

            if "transcribed" not in st.session_state:

                with st.status('Delar upp ljudfilen i mindre bitar...'):
                    chunk_paths = split_audio_to_chunks(audio)

                # Transcribe chunks in parallel
                with st.status('Transkriberar alla ljudbitar. Det h√§r kan ta ett tag beroende p√• l√•ng inspelningen √§r...'):
                    with ThreadPoolExecutor() as executor:
                        # Open each chunk as a file object and pass it to transcribe_with_whisper_openai
                        transcriptions = list(executor.map(
                            lambda chunk: transcribe_with_whisper_openai(open(chunk, "rb"), os.path.basename(chunk)), 
                            chunk_paths
                        )) 
                        # Combine all the transcriptions into one
                        st.session_state.transcribed = "\n".join(transcriptions)
            
            st.markdown("#### Ditt ber√∂m")
            st.write(st.session_state.transcribed)



    with maincol2:

        st.markdown("#### Skapa AI-ber√∂m")

        if "transcribed" in st.session_state:

            system_prompt = ""

            gpt_template = st.selectbox(
                "V√§lj mall", 
                ["V√§lj mall", 
                 "Ljus r√∂st - Glad, positiv och sv√§r g√§rna",
                 "Ljus r√∂st - Korrekt myndighetsperson",
                 "Djup r√∂st - F√•ordig men glad och rolig",
                 "Djup r√∂st - Skojfrisk och sv√§rande"

                 ],
                index=[
                 "Ljus r√∂st - Glad, positiv och sv√§r g√§rna",
                 "Ljus r√∂st - Korrekt myndighetsperson",
                 "Djup r√∂st - F√•ordig men glad och rolig",
                 "Djup r√∂st - Skojfrisk och sv√§rande"
                ].index(st.session_state["gpt_template"]),
            )

            if gpt_template == "Ljus r√∂st - Glad, positiv och sv√§r g√§rna":
                system_prompt = p.ljus_rost_1
            
            elif gpt_template == "Ljus r√∂st - Korrekt myndighetsperson":
                system_prompt = p.ljus_rost_2
            
            elif gpt_template == "Djup r√∂st - F√•ordig men glad och rolig":
                system_prompt = p.djup_rost_1

            elif gpt_template == "Djup r√∂st - Skojfrisk och sv√§rande":
                system_prompt = p.djup_rost_2


            with st.popover("Visa prompt"):
                st.write(system_prompt)


            if gpt_template != "V√§lj mall":
                
                llm_model = st.session_state["llm_chat_model"]
                llm_temp = st.session_state["llm_temperature"]
                
                if "llama" in llm_model:
                    full_response = process_text(llm_model, llm_temp, system_prompt, st.session_state.transcribed)
                else:
                    full_response = process_text_openai(llm_model, llm_temp, system_prompt, st.session_state.transcribed)
                
                if gpt_template == "Ljus r√∂st - Glad, positiv och sv√§r g√§rna": # Sanna upp√•t

                    voice = "4xkUqaR9MYOJHoaC1Nak"
                    stability = 0.3
                    similarity_boost = 0.86
                    
                    with st.spinner(text="L√§ser in din text..."):
                        tts_audio = text_to_speech(full_response, voice, stability, similarity_boost)

                    with st.spinner(text="Mixar musik och r√∂st..."):
                            mix_music_and_voice("low")
                            st.audio("data/audio/mixed_audio.mp3", format="audio/mpeg", loop=False)
                
                elif gpt_template == "Ljus r√∂st - Korrekt myndighetsperson": # Sanna

                    voice = "aSLKtNoVBZlxQEMsnGL2"
                    stability = 0.5
                    similarity_boost = 0.75
                    
                    with st.spinner(text="L√§ser in din text..."):
                        tts_audio = text_to_speech(full_response, voice, stability, similarity_boost)

                    with st.spinner(text="Mixar musik och r√∂st..."):
                            mix_music_and_voice("low")
                            st.audio("data/audio/mixed_audio.mp3", format="audio/mpeg", loop=False)

                elif gpt_template == "Djup r√∂st - F√•ordig men glad och rolig": # Jonas

                    voice = "e6OiUVixGLmvtdn2GJYE"
                    stability = 0.71
                    similarity_boost = 0.48
                    
                    with st.spinner(text="L√§ser in din text..."):
                        tts_audio = text_to_speech(full_response, voice, stability, similarity_boost)

                    with st.spinner(text="Mixar musik och r√∂st..."):
                            mix_music_and_voice("high")
                            st.audio("data/audio/mixed_audio.mp3", format="audio/mpeg", loop=False)

                elif gpt_template == "Djup r√∂st - Skojfrisk och sv√§rande": # Dave

                    voice = "m8oYKlEB8ecBLgKRMcwy"
                    stability = 0.5
                    similarity_boost = 0.6
                    
                    with st.spinner(text="L√§ser in din text..."):
                        tts_audio = text_to_speech(full_response, voice, stability, similarity_boost)

                    with st.spinner(text="Mixar musik och r√∂st..."):
                            mix_music_and_voice("medium")
                            st.audio("data/audio/mixed_audio.mp3", format="audio/mpeg", loop=False)
                
                else:
                    pass
                

if __name__ == "__main__":
    main()



